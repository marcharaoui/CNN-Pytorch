{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dKvR81eJ8jEq",
        "-IshKHFN8bf-",
        "QvpyqGft-JPQ",
        "HuvuKBkmAZ8N",
        "9r3AbzX3BcL1",
        "Uhw4XPDSBiXO",
        "eXiPaqedCrr9",
        "BhYkhKT3FeUV",
        "PnC5e91rKExb",
        "y_Q5c71mM14f",
        "GXw0JHhxKa-b",
        "JFNFYeMkMZxm"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN using Pytorch\n",
        "\n",
        "This is a basic CNN template code for anyone to use!"
      ],
      "metadata": {
        "id": "QA7zUxz97uvm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RHycMlybx0bZ"
      },
      "outputs": [],
      "source": [
        "# @title Basic convolutional neural network code in Pytorch #opensource\n",
        "# @markdown Author: Marc Haraoui\n",
        "\n",
        "# @markdown Year of update: 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and versions"
      ],
      "metadata": {
        "id": "dKvR81eJ8jEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzTGV1v38f99",
        "outputId": "baf9513e-12ec-45fa-ff46-66b6599f3940"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skZNsWwL8uwO",
        "outputId": "6bbd9f04-fc45-4f98-cd4b-7dd244c8e248"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 22 12:32:54 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if cuda is available\n",
        "print(f\"Is cuda available? {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn0MhoyT9DzW",
        "outputId": "5d2b1614-76b0-4653-d7d8-3312620cb07c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is cuda available? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DIY CNN with Pytorch"
      ],
      "metadata": {
        "id": "-IshKHFN8bf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN Class"
      ],
      "metadata": {
        "id": "QvpyqGft-JPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BasicCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # 1 channel (input) to 10 channels (output)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # 10 to 20\n",
        "    self.fc1 = nn.Linear(320, 50) # Fully connected MLP with 320 inputs and 50 outputs\n",
        "    self.fc2 = nn.Linear(50, 10) #  MLP: 50 inputs et 10 output classes\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.conv1(x)\n",
        "    out = F.max_pool2d(out, 2) # downsampling operation\n",
        "    out = F.relu(out) # relu activation function\n",
        "    out = F.relu(F.max_pool2d(self.conv2(out), 2)) # same as three previous lines\n",
        "    out = out.view(-1, 320)\n",
        "    out = F.relu(self.fc1(out))\n",
        "    out = self.fc2(out)\n",
        "    return F.log_softmax(out, dim=1) # last activation function (probability distribution)"
      ],
      "metadata": {
        "id": "NpaMh4nL-L18"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MNIST Dataset"
      ],
      "metadata": {
        "id": "HuvuKBkmAZ8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "# Numpy array to pytorch tensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Get MNIST dataset for training\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "download=True, transform=transform)\n",
        "\n",
        "# Create the train loader\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "shuffle=True, num_workers=2)\n",
        "\n",
        "# Get MNIST dataset for test\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "download=True, transform=transform)\n",
        "\n",
        "#Create the test loader\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mm1gyjiAd5t",
        "outputId": "beffb1e0-db9a-457e-9e7a-e87379541947"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 101842094.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 72666882.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 27422141.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 23519171.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training our CNN"
      ],
      "metadata": {
        "id": "9r3AbzX3BcL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model init and SGD optimizer\n",
        "\n",
        "-> You can use another one such as Adam or variations."
      ],
      "metadata": {
        "id": "Uhw4XPDSBiXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cuda = torch.device('cuda')\n",
        "\n",
        "# Initializing the model on cuda\n",
        "our_model = BasicCNN().to(cuda)\n",
        "\n",
        "# SGD optimizer with a e-2 learning rate (you can use a scheduler if necessary)\n",
        "optimizer = optim.SGD(our_model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "GOaB2QcpBSuh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and Test functions"
      ],
      "metadata": {
        "id": "eXiPaqedCrr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, optimizer, epoch, cuda=cuda):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(loader):\n",
        "    data = data.to(cuda)\n",
        "    target = target.to(cuda)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Predictions per batch\n",
        "    output = model(data)\n",
        "\n",
        "    # Loss\n",
        "    loss = F.cross_entropy(output, target)\n",
        "    loss.backward() # back propagation\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print result and save checkpoint every 10 batch\n",
        "    if batch_idx % 10 == 0:\n",
        "      print('Train epoch {}: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data),\n",
        "            len(loader.dataset),100. * batch_idx / len(loader), loss.item()))\n",
        "\n",
        "def test(model, loader, cuda=cuda):\n",
        "  model.eval()\n",
        "  loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad(): # no gradient in eval mode\n",
        "    for data, target in loader:\n",
        "      data = data.to(cuda)\n",
        "      target = target.to(cuda)\n",
        "\n",
        "      # Predictions per batch\n",
        "      output = model(data)\n",
        "\n",
        "      # Loss\n",
        "      loss += F.nll_loss(output, target, reduction='sum').item() # negative log likelihood loss\n",
        "      prediction = output.max(1, keepdim=True)[1]\n",
        "      correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
        "      loss /= len(loader.dataset)\n",
        "\n",
        "      # Print results\n",
        "      print('Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            loss, correct, len(loader.dataset), 100. * correct / len(loader.dataset)))"
      ],
      "metadata": {
        "id": "Agbd4RlwCvhQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train and test the model for 3 epochs"
      ],
      "metadata": {
        "id": "BhYkhKT3FeUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 3\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "    train(our_model, trainloader, optimizer, epoch, cuda)\n",
        "    test(our_model, testloader, cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fwKbvVKFgmq",
        "outputId": "c6c50f34-d7e2-4169-f803-a86e50201210"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch 0: [0/60000 (0%)]\tLoss: 0.019460\n",
            "Train epoch 0: [320/60000 (1%)]\tLoss: 0.009177\n",
            "Train epoch 0: [640/60000 (1%)]\tLoss: 0.019114\n",
            "Train epoch 0: [960/60000 (2%)]\tLoss: 0.000214\n",
            "Train epoch 0: [1280/60000 (2%)]\tLoss: 0.000275\n",
            "Train epoch 0: [1600/60000 (3%)]\tLoss: 0.007748\n",
            "Train epoch 0: [1920/60000 (3%)]\tLoss: 0.004060\n",
            "Train epoch 0: [2240/60000 (4%)]\tLoss: 0.006806\n",
            "Train epoch 0: [2560/60000 (4%)]\tLoss: 0.012380\n",
            "Train epoch 0: [2880/60000 (5%)]\tLoss: 0.013040\n",
            "Train epoch 0: [3200/60000 (5%)]\tLoss: 0.002067\n",
            "Train epoch 0: [3520/60000 (6%)]\tLoss: 0.059228\n",
            "Train epoch 0: [3840/60000 (6%)]\tLoss: 0.023873\n",
            "Train epoch 0: [4160/60000 (7%)]\tLoss: 0.000214\n",
            "Train epoch 0: [4480/60000 (7%)]\tLoss: 0.003368\n",
            "Train epoch 0: [4800/60000 (8%)]\tLoss: 0.062612\n",
            "Train epoch 0: [5120/60000 (9%)]\tLoss: 0.051413\n",
            "Train epoch 0: [5440/60000 (9%)]\tLoss: 0.155081\n",
            "Train epoch 0: [5760/60000 (10%)]\tLoss: 0.033838\n",
            "Train epoch 0: [6080/60000 (10%)]\tLoss: 0.003122\n",
            "Train epoch 0: [6400/60000 (11%)]\tLoss: 0.001975\n",
            "Train epoch 0: [6720/60000 (11%)]\tLoss: 0.007376\n",
            "Train epoch 0: [7040/60000 (12%)]\tLoss: 0.032275\n",
            "Train epoch 0: [7360/60000 (12%)]\tLoss: 0.016877\n",
            "Train epoch 0: [7680/60000 (13%)]\tLoss: 0.006627\n",
            "Train epoch 0: [8000/60000 (13%)]\tLoss: 0.000617\n",
            "Train epoch 0: [8320/60000 (14%)]\tLoss: 0.008068\n",
            "Train epoch 0: [8640/60000 (14%)]\tLoss: 0.039650\n",
            "Train epoch 0: [8960/60000 (15%)]\tLoss: 0.229160\n",
            "Train epoch 0: [9280/60000 (15%)]\tLoss: 0.003555\n",
            "Train epoch 0: [9600/60000 (16%)]\tLoss: 0.132708\n",
            "Train epoch 0: [9920/60000 (17%)]\tLoss: 0.001390\n",
            "Train epoch 0: [10240/60000 (17%)]\tLoss: 0.007504\n",
            "Train epoch 0: [10560/60000 (18%)]\tLoss: 0.002252\n",
            "Train epoch 0: [10880/60000 (18%)]\tLoss: 0.013138\n",
            "Train epoch 0: [11200/60000 (19%)]\tLoss: 0.036466\n",
            "Train epoch 0: [11520/60000 (19%)]\tLoss: 0.025843\n",
            "Train epoch 0: [11840/60000 (20%)]\tLoss: 0.005233\n",
            "Train epoch 0: [12160/60000 (20%)]\tLoss: 0.003875\n",
            "Train epoch 0: [12480/60000 (21%)]\tLoss: 0.001066\n",
            "Train epoch 0: [12800/60000 (21%)]\tLoss: 0.017375\n",
            "Train epoch 0: [13120/60000 (22%)]\tLoss: 0.179273\n",
            "Train epoch 0: [13440/60000 (22%)]\tLoss: 0.008211\n",
            "Train epoch 0: [13760/60000 (23%)]\tLoss: 0.142244\n",
            "Train epoch 0: [14080/60000 (23%)]\tLoss: 0.014488\n",
            "Train epoch 0: [14400/60000 (24%)]\tLoss: 0.004591\n",
            "Train epoch 0: [14720/60000 (25%)]\tLoss: 0.005360\n",
            "Train epoch 0: [15040/60000 (25%)]\tLoss: 0.058944\n",
            "Train epoch 0: [15360/60000 (26%)]\tLoss: 0.052581\n",
            "Train epoch 0: [15680/60000 (26%)]\tLoss: 0.018774\n",
            "Train epoch 0: [16000/60000 (27%)]\tLoss: 0.080661\n",
            "Train epoch 0: [16320/60000 (27%)]\tLoss: 0.002395\n",
            "Train epoch 0: [16640/60000 (28%)]\tLoss: 0.003365\n",
            "Train epoch 0: [16960/60000 (28%)]\tLoss: 0.020950\n",
            "Train epoch 0: [17280/60000 (29%)]\tLoss: 0.015840\n",
            "Train epoch 0: [17600/60000 (29%)]\tLoss: 0.000543\n",
            "Train epoch 0: [17920/60000 (30%)]\tLoss: 0.001628\n",
            "Train epoch 0: [18240/60000 (30%)]\tLoss: 0.019460\n",
            "Train epoch 0: [18560/60000 (31%)]\tLoss: 0.172593\n",
            "Train epoch 0: [18880/60000 (31%)]\tLoss: 0.045096\n",
            "Train epoch 0: [19200/60000 (32%)]\tLoss: 0.002375\n",
            "Train epoch 0: [19520/60000 (33%)]\tLoss: 0.000192\n",
            "Train epoch 0: [19840/60000 (33%)]\tLoss: 0.092438\n",
            "Train epoch 0: [20160/60000 (34%)]\tLoss: 0.008233\n",
            "Train epoch 0: [20480/60000 (34%)]\tLoss: 0.157670\n",
            "Train epoch 0: [20800/60000 (35%)]\tLoss: 0.007715\n",
            "Train epoch 0: [21120/60000 (35%)]\tLoss: 0.068495\n",
            "Train epoch 0: [21440/60000 (36%)]\tLoss: 0.004827\n",
            "Train epoch 0: [21760/60000 (36%)]\tLoss: 0.000727\n",
            "Train epoch 0: [22080/60000 (37%)]\tLoss: 0.018512\n",
            "Train epoch 0: [22400/60000 (37%)]\tLoss: 0.002872\n",
            "Train epoch 0: [22720/60000 (38%)]\tLoss: 0.010615\n",
            "Train epoch 0: [23040/60000 (38%)]\tLoss: 0.004618\n",
            "Train epoch 0: [23360/60000 (39%)]\tLoss: 0.072848\n",
            "Train epoch 0: [23680/60000 (39%)]\tLoss: 0.014981\n",
            "Train epoch 0: [24000/60000 (40%)]\tLoss: 0.003909\n",
            "Train epoch 0: [24320/60000 (41%)]\tLoss: 0.002854\n",
            "Train epoch 0: [24640/60000 (41%)]\tLoss: 0.013461\n",
            "Train epoch 0: [24960/60000 (42%)]\tLoss: 0.177508\n",
            "Train epoch 0: [25280/60000 (42%)]\tLoss: 0.002539\n",
            "Train epoch 0: [25600/60000 (43%)]\tLoss: 0.030950\n",
            "Train epoch 0: [25920/60000 (43%)]\tLoss: 0.004137\n",
            "Train epoch 0: [26240/60000 (44%)]\tLoss: 0.055799\n",
            "Train epoch 0: [26560/60000 (44%)]\tLoss: 0.273088\n",
            "Train epoch 0: [26880/60000 (45%)]\tLoss: 0.014990\n",
            "Train epoch 0: [27200/60000 (45%)]\tLoss: 0.006165\n",
            "Train epoch 0: [27520/60000 (46%)]\tLoss: 0.003730\n",
            "Train epoch 0: [27840/60000 (46%)]\tLoss: 0.121244\n",
            "Train epoch 0: [28160/60000 (47%)]\tLoss: 0.014525\n",
            "Train epoch 0: [28480/60000 (47%)]\tLoss: 0.018007\n",
            "Train epoch 0: [28800/60000 (48%)]\tLoss: 0.031598\n",
            "Train epoch 0: [29120/60000 (49%)]\tLoss: 0.003157\n",
            "Train epoch 0: [29440/60000 (49%)]\tLoss: 0.042880\n",
            "Train epoch 0: [29760/60000 (50%)]\tLoss: 0.067939\n",
            "Train epoch 0: [30080/60000 (50%)]\tLoss: 0.001106\n",
            "Train epoch 0: [30400/60000 (51%)]\tLoss: 0.034892\n",
            "Train epoch 0: [30720/60000 (51%)]\tLoss: 0.001104\n",
            "Train epoch 0: [31040/60000 (52%)]\tLoss: 0.004476\n",
            "Train epoch 0: [31360/60000 (52%)]\tLoss: 0.006691\n",
            "Train epoch 0: [31680/60000 (53%)]\tLoss: 0.061665\n",
            "Train epoch 0: [32000/60000 (53%)]\tLoss: 0.083016\n",
            "Train epoch 0: [32320/60000 (54%)]\tLoss: 0.061524\n",
            "Train epoch 0: [32640/60000 (54%)]\tLoss: 0.003125\n",
            "Train epoch 0: [32960/60000 (55%)]\tLoss: 0.002648\n",
            "Train epoch 0: [33280/60000 (55%)]\tLoss: 0.008801\n",
            "Train epoch 0: [33600/60000 (56%)]\tLoss: 0.006809\n",
            "Train epoch 0: [33920/60000 (57%)]\tLoss: 0.101547\n",
            "Train epoch 0: [34240/60000 (57%)]\tLoss: 0.005267\n",
            "Train epoch 0: [34560/60000 (58%)]\tLoss: 0.002000\n",
            "Train epoch 0: [34880/60000 (58%)]\tLoss: 0.015131\n",
            "Train epoch 0: [35200/60000 (59%)]\tLoss: 0.000231\n",
            "Train epoch 0: [35520/60000 (59%)]\tLoss: 0.010618\n",
            "Train epoch 0: [35840/60000 (60%)]\tLoss: 0.053427\n",
            "Train epoch 0: [36160/60000 (60%)]\tLoss: 0.247984\n",
            "Train epoch 0: [36480/60000 (61%)]\tLoss: 0.003463\n",
            "Train epoch 0: [36800/60000 (61%)]\tLoss: 0.045864\n",
            "Train epoch 0: [37120/60000 (62%)]\tLoss: 0.051700\n",
            "Train epoch 0: [37440/60000 (62%)]\tLoss: 0.011610\n",
            "Train epoch 0: [37760/60000 (63%)]\tLoss: 0.320562\n",
            "Train epoch 0: [38080/60000 (63%)]\tLoss: 0.012037\n",
            "Train epoch 0: [38400/60000 (64%)]\tLoss: 0.000734\n",
            "Train epoch 0: [38720/60000 (65%)]\tLoss: 0.001896\n",
            "Train epoch 0: [39040/60000 (65%)]\tLoss: 0.001864\n",
            "Train epoch 0: [39360/60000 (66%)]\tLoss: 0.091095\n",
            "Train epoch 0: [39680/60000 (66%)]\tLoss: 0.018481\n",
            "Train epoch 0: [40000/60000 (67%)]\tLoss: 0.003708\n",
            "Train epoch 0: [40320/60000 (67%)]\tLoss: 0.009157\n",
            "Train epoch 0: [40640/60000 (68%)]\tLoss: 0.039581\n",
            "Train epoch 0: [40960/60000 (68%)]\tLoss: 0.189488\n",
            "Train epoch 0: [41280/60000 (69%)]\tLoss: 0.001214\n",
            "Train epoch 0: [41600/60000 (69%)]\tLoss: 0.002625\n",
            "Train epoch 0: [41920/60000 (70%)]\tLoss: 0.013553\n",
            "Train epoch 0: [42240/60000 (70%)]\tLoss: 0.037054\n",
            "Train epoch 0: [42560/60000 (71%)]\tLoss: 0.019536\n",
            "Train epoch 0: [42880/60000 (71%)]\tLoss: 0.072941\n",
            "Train epoch 0: [43200/60000 (72%)]\tLoss: 0.115232\n",
            "Train epoch 0: [43520/60000 (73%)]\tLoss: 0.035317\n",
            "Train epoch 0: [43840/60000 (73%)]\tLoss: 0.004205\n",
            "Train epoch 0: [44160/60000 (74%)]\tLoss: 0.010980\n",
            "Train epoch 0: [44480/60000 (74%)]\tLoss: 0.000580\n",
            "Train epoch 0: [44800/60000 (75%)]\tLoss: 0.006859\n",
            "Train epoch 0: [45120/60000 (75%)]\tLoss: 0.006323\n",
            "Train epoch 0: [45440/60000 (76%)]\tLoss: 0.017110\n",
            "Train epoch 0: [45760/60000 (76%)]\tLoss: 0.008125\n",
            "Train epoch 0: [46080/60000 (77%)]\tLoss: 0.007161\n",
            "Train epoch 0: [46400/60000 (77%)]\tLoss: 0.006596\n",
            "Train epoch 0: [46720/60000 (78%)]\tLoss: 0.036727\n",
            "Train epoch 0: [47040/60000 (78%)]\tLoss: 0.031309\n",
            "Train epoch 0: [47360/60000 (79%)]\tLoss: 0.000683\n",
            "Train epoch 0: [47680/60000 (79%)]\tLoss: 0.002705\n",
            "Train epoch 0: [48000/60000 (80%)]\tLoss: 0.007988\n",
            "Train epoch 0: [48320/60000 (81%)]\tLoss: 0.008243\n",
            "Train epoch 0: [48640/60000 (81%)]\tLoss: 0.000294\n",
            "Train epoch 0: [48960/60000 (82%)]\tLoss: 0.053447\n",
            "Train epoch 0: [49280/60000 (82%)]\tLoss: 0.003111\n",
            "Train epoch 0: [49600/60000 (83%)]\tLoss: 0.002960\n",
            "Train epoch 0: [49920/60000 (83%)]\tLoss: 0.003356\n",
            "Train epoch 0: [50240/60000 (84%)]\tLoss: 0.006549\n",
            "Train epoch 0: [50560/60000 (84%)]\tLoss: 0.001299\n",
            "Train epoch 0: [50880/60000 (85%)]\tLoss: 0.006804\n",
            "Train epoch 0: [51200/60000 (85%)]\tLoss: 0.004968\n",
            "Train epoch 0: [51520/60000 (86%)]\tLoss: 0.035149\n",
            "Train epoch 0: [51840/60000 (86%)]\tLoss: 0.006102\n",
            "Train epoch 0: [52160/60000 (87%)]\tLoss: 0.008828\n",
            "Train epoch 0: [52480/60000 (87%)]\tLoss: 0.002406\n",
            "Train epoch 0: [52800/60000 (88%)]\tLoss: 0.001175\n",
            "Train epoch 0: [53120/60000 (89%)]\tLoss: 0.040248\n",
            "Train epoch 0: [53440/60000 (89%)]\tLoss: 0.009673\n",
            "Train epoch 0: [53760/60000 (90%)]\tLoss: 0.020093\n",
            "Train epoch 0: [54080/60000 (90%)]\tLoss: 0.001167\n",
            "Train epoch 0: [54400/60000 (91%)]\tLoss: 0.012491\n",
            "Train epoch 0: [54720/60000 (91%)]\tLoss: 0.004269\n",
            "Train epoch 0: [55040/60000 (92%)]\tLoss: 0.000734\n",
            "Train epoch 0: [55360/60000 (92%)]\tLoss: 0.023642\n",
            "Train epoch 0: [55680/60000 (93%)]\tLoss: 0.002259\n",
            "Train epoch 0: [56000/60000 (93%)]\tLoss: 0.002800\n",
            "Train epoch 0: [56320/60000 (94%)]\tLoss: 0.113019\n",
            "Train epoch 0: [56640/60000 (94%)]\tLoss: 0.000499\n",
            "Train epoch 0: [56960/60000 (95%)]\tLoss: 0.003344\n",
            "Train epoch 0: [57280/60000 (95%)]\tLoss: 0.009313\n",
            "Train epoch 0: [57600/60000 (96%)]\tLoss: 0.023106\n",
            "Train epoch 0: [57920/60000 (97%)]\tLoss: 0.029983\n",
            "Train epoch 0: [58240/60000 (97%)]\tLoss: 0.185296\n",
            "Train epoch 0: [58560/60000 (98%)]\tLoss: 0.033243\n",
            "Train epoch 0: [58880/60000 (98%)]\tLoss: 0.095164\n",
            "Train epoch 0: [59200/60000 (99%)]\tLoss: 0.023891\n",
            "Train epoch 0: [59520/60000 (99%)]\tLoss: 0.001400\n",
            "Train epoch 0: [59840/60000 (100%)]\tLoss: 0.098513\n",
            "Test: Average loss: 0.0000, Accuracy: 32/10000 (0%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 64/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 95/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 127/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 159/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 191/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 223/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 254/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 285/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 317/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 348/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 380/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 412/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 443/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 474/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 506/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 538/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 570/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 601/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 632/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 663/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 695/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 726/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 757/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 788/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 820/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 852/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 884/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 915/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 946/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 977/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 1008/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1040/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1072/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1104/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1136/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1168/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1200/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0009, Accuracy: 1228/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1259/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1291/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 1321/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1353/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 1384/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1415/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1446/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1478/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1508/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1539/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1571/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1603/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1635/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1666/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1698/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1729/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1761/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1793/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1825/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 1856/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 1887/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1919/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1951/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1983/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0009, Accuracy: 2012/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2043/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2074/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 2104/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2136/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2168/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2200/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2232/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2264/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2296/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2328/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2360/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2391/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2423/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2455/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2487/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2519/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2550/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 2581/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 2612/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2644/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2676/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2707/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2738/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2770/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2802/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2834/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 2865/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0010, Accuracy: 2893/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2924/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2956/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2987/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3019/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3051/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3082/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3114/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3146/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3178/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3210/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3242/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3274/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3306/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3338/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0008, Accuracy: 3369/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3401/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3432/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3464/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0017, Accuracy: 3494/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0009, Accuracy: 3523/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3555/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3587/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3619/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3651/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3682/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3714/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3745/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3777/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3807/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3839/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3870/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3901/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3933/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3965/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3997/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4028/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4060/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4092/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 4122/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4154/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 4184/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4215/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4247/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4279/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4311/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4343/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4374/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4406/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4437/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4469/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 4499/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4531/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4563/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4595/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4627/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 4658/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 4688/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4720/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 4750/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4782/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4814/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4846/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4878/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4910/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4942/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4974/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5006/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5038/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5070/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5102/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5133/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5165/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 5196/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5228/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5260/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5292/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5324/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5356/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5388/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5420/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5452/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5484/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5516/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5548/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5580/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5612/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5644/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5676/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5708/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5740/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5772/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5804/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5836/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 5867/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 5897/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 5928/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5960/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5992/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6024/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6056/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 6088/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6120/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6152/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6184/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6216/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6248/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6280/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6312/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6344/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6376/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6408/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6440/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 6471/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 6500/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0009, Accuracy: 6530/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 6560/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6592/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6624/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6656/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 6687/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6719/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6751/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6783/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6815/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6847/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6879/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6911/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6943/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6975/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7007/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7039/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7071/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7103/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7135/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7167/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7199/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7231/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7263/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7295/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7327/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7359/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7391/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7423/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7455/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7487/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7519/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7551/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7583/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7615/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7647/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7679/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7711/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7743/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 7773/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7805/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 7836/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7868/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7900/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7932/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7964/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 7996/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8028/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8060/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8092/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8124/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8156/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8188/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8219/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8251/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8283/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8314/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8346/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8378/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8410/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8442/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8474/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8506/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8538/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8570/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8602/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8634/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8666/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8698/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8730/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8762/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8794/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8826/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8858/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8890/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 8921/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8953/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8985/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9017/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9049/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9081/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9113/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9145/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9177/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9209/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9241/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9273/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9305/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9337/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9369/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9401/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9433/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9465/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9497/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9529/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 9559/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0008, Accuracy: 9588/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 9619/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0008, Accuracy: 9648/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 9679/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9711/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 9742/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9774/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 9804/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9836/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9868/10000 (99%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9884/10000 (99%)\n",
            "\n",
            "Train epoch 1: [0/60000 (0%)]\tLoss: 0.000426\n",
            "Train epoch 1: [320/60000 (1%)]\tLoss: 0.004148\n",
            "Train epoch 1: [640/60000 (1%)]\tLoss: 0.002537\n",
            "Train epoch 1: [960/60000 (2%)]\tLoss: 0.007462\n",
            "Train epoch 1: [1280/60000 (2%)]\tLoss: 0.056885\n",
            "Train epoch 1: [1600/60000 (3%)]\tLoss: 0.010214\n",
            "Train epoch 1: [1920/60000 (3%)]\tLoss: 0.004432\n",
            "Train epoch 1: [2240/60000 (4%)]\tLoss: 0.002573\n",
            "Train epoch 1: [2560/60000 (4%)]\tLoss: 0.005945\n",
            "Train epoch 1: [2880/60000 (5%)]\tLoss: 0.012127\n",
            "Train epoch 1: [3200/60000 (5%)]\tLoss: 0.003764\n",
            "Train epoch 1: [3520/60000 (6%)]\tLoss: 0.092601\n",
            "Train epoch 1: [3840/60000 (6%)]\tLoss: 0.017983\n",
            "Train epoch 1: [4160/60000 (7%)]\tLoss: 0.001080\n",
            "Train epoch 1: [4480/60000 (7%)]\tLoss: 0.001734\n",
            "Train epoch 1: [4800/60000 (8%)]\tLoss: 0.000319\n",
            "Train epoch 1: [5120/60000 (9%)]\tLoss: 0.023374\n",
            "Train epoch 1: [5440/60000 (9%)]\tLoss: 0.001856\n",
            "Train epoch 1: [5760/60000 (10%)]\tLoss: 0.018441\n",
            "Train epoch 1: [6080/60000 (10%)]\tLoss: 0.014773\n",
            "Train epoch 1: [6400/60000 (11%)]\tLoss: 0.003081\n",
            "Train epoch 1: [6720/60000 (11%)]\tLoss: 0.000319\n",
            "Train epoch 1: [7040/60000 (12%)]\tLoss: 0.000578\n",
            "Train epoch 1: [7360/60000 (12%)]\tLoss: 0.001358\n",
            "Train epoch 1: [7680/60000 (13%)]\tLoss: 0.029933\n",
            "Train epoch 1: [8000/60000 (13%)]\tLoss: 0.009978\n",
            "Train epoch 1: [8320/60000 (14%)]\tLoss: 0.020663\n",
            "Train epoch 1: [8640/60000 (14%)]\tLoss: 0.033958\n",
            "Train epoch 1: [8960/60000 (15%)]\tLoss: 0.003447\n",
            "Train epoch 1: [9280/60000 (15%)]\tLoss: 0.011883\n",
            "Train epoch 1: [9600/60000 (16%)]\tLoss: 0.017094\n",
            "Train epoch 1: [9920/60000 (17%)]\tLoss: 0.016532\n",
            "Train epoch 1: [10240/60000 (17%)]\tLoss: 0.003406\n",
            "Train epoch 1: [10560/60000 (18%)]\tLoss: 0.054667\n",
            "Train epoch 1: [10880/60000 (18%)]\tLoss: 0.007810\n",
            "Train epoch 1: [11200/60000 (19%)]\tLoss: 0.001524\n",
            "Train epoch 1: [11520/60000 (19%)]\tLoss: 0.002255\n",
            "Train epoch 1: [11840/60000 (20%)]\tLoss: 0.038700\n",
            "Train epoch 1: [12160/60000 (20%)]\tLoss: 0.012949\n",
            "Train epoch 1: [12480/60000 (21%)]\tLoss: 0.014440\n",
            "Train epoch 1: [12800/60000 (21%)]\tLoss: 0.005453\n",
            "Train epoch 1: [13120/60000 (22%)]\tLoss: 0.006540\n",
            "Train epoch 1: [13440/60000 (22%)]\tLoss: 0.180616\n",
            "Train epoch 1: [13760/60000 (23%)]\tLoss: 0.005596\n",
            "Train epoch 1: [14080/60000 (23%)]\tLoss: 0.001009\n",
            "Train epoch 1: [14400/60000 (24%)]\tLoss: 0.079567\n",
            "Train epoch 1: [14720/60000 (25%)]\tLoss: 0.003460\n",
            "Train epoch 1: [15040/60000 (25%)]\tLoss: 0.008934\n",
            "Train epoch 1: [15360/60000 (26%)]\tLoss: 0.003529\n",
            "Train epoch 1: [15680/60000 (26%)]\tLoss: 0.009413\n",
            "Train epoch 1: [16000/60000 (27%)]\tLoss: 0.009822\n",
            "Train epoch 1: [16320/60000 (27%)]\tLoss: 0.001293\n",
            "Train epoch 1: [16640/60000 (28%)]\tLoss: 0.000299\n",
            "Train epoch 1: [16960/60000 (28%)]\tLoss: 0.009302\n",
            "Train epoch 1: [17280/60000 (29%)]\tLoss: 0.088371\n",
            "Train epoch 1: [17600/60000 (29%)]\tLoss: 0.004989\n",
            "Train epoch 1: [17920/60000 (30%)]\tLoss: 0.142555\n",
            "Train epoch 1: [18240/60000 (30%)]\tLoss: 0.245500\n",
            "Train epoch 1: [18560/60000 (31%)]\tLoss: 0.011235\n",
            "Train epoch 1: [18880/60000 (31%)]\tLoss: 0.007554\n",
            "Train epoch 1: [19200/60000 (32%)]\tLoss: 0.001383\n",
            "Train epoch 1: [19520/60000 (33%)]\tLoss: 0.000321\n",
            "Train epoch 1: [19840/60000 (33%)]\tLoss: 0.003407\n",
            "Train epoch 1: [20160/60000 (34%)]\tLoss: 0.005148\n",
            "Train epoch 1: [20480/60000 (34%)]\tLoss: 0.006275\n",
            "Train epoch 1: [20800/60000 (35%)]\tLoss: 0.076767\n",
            "Train epoch 1: [21120/60000 (35%)]\tLoss: 0.022405\n",
            "Train epoch 1: [21440/60000 (36%)]\tLoss: 0.062042\n",
            "Train epoch 1: [21760/60000 (36%)]\tLoss: 0.015122\n",
            "Train epoch 1: [22080/60000 (37%)]\tLoss: 0.003359\n",
            "Train epoch 1: [22400/60000 (37%)]\tLoss: 0.003047\n",
            "Train epoch 1: [22720/60000 (38%)]\tLoss: 0.000283\n",
            "Train epoch 1: [23040/60000 (38%)]\tLoss: 0.004364\n",
            "Train epoch 1: [23360/60000 (39%)]\tLoss: 0.002729\n",
            "Train epoch 1: [23680/60000 (39%)]\tLoss: 0.000177\n",
            "Train epoch 1: [24000/60000 (40%)]\tLoss: 0.016103\n",
            "Train epoch 1: [24320/60000 (41%)]\tLoss: 0.001056\n",
            "Train epoch 1: [24640/60000 (41%)]\tLoss: 0.000196\n",
            "Train epoch 1: [24960/60000 (42%)]\tLoss: 0.011853\n",
            "Train epoch 1: [25280/60000 (42%)]\tLoss: 0.002187\n",
            "Train epoch 1: [25600/60000 (43%)]\tLoss: 0.001614\n",
            "Train epoch 1: [25920/60000 (43%)]\tLoss: 0.005778\n",
            "Train epoch 1: [26240/60000 (44%)]\tLoss: 0.006358\n",
            "Train epoch 1: [26560/60000 (44%)]\tLoss: 0.025713\n",
            "Train epoch 1: [26880/60000 (45%)]\tLoss: 0.121306\n",
            "Train epoch 1: [27200/60000 (45%)]\tLoss: 0.171443\n",
            "Train epoch 1: [27520/60000 (46%)]\tLoss: 0.029082\n",
            "Train epoch 1: [27840/60000 (46%)]\tLoss: 0.024297\n",
            "Train epoch 1: [28160/60000 (47%)]\tLoss: 0.006357\n",
            "Train epoch 1: [28480/60000 (47%)]\tLoss: 0.001833\n",
            "Train epoch 1: [28800/60000 (48%)]\tLoss: 0.009061\n",
            "Train epoch 1: [29120/60000 (49%)]\tLoss: 0.118076\n",
            "Train epoch 1: [29440/60000 (49%)]\tLoss: 0.002230\n",
            "Train epoch 1: [29760/60000 (50%)]\tLoss: 0.000540\n",
            "Train epoch 1: [30080/60000 (50%)]\tLoss: 0.004084\n",
            "Train epoch 1: [30400/60000 (51%)]\tLoss: 0.006033\n",
            "Train epoch 1: [30720/60000 (51%)]\tLoss: 0.196351\n",
            "Train epoch 1: [31040/60000 (52%)]\tLoss: 0.003397\n",
            "Train epoch 1: [31360/60000 (52%)]\tLoss: 0.008981\n",
            "Train epoch 1: [31680/60000 (53%)]\tLoss: 0.029899\n",
            "Train epoch 1: [32000/60000 (53%)]\tLoss: 0.047229\n",
            "Train epoch 1: [32320/60000 (54%)]\tLoss: 0.005373\n",
            "Train epoch 1: [32640/60000 (54%)]\tLoss: 0.008703\n",
            "Train epoch 1: [32960/60000 (55%)]\tLoss: 0.059820\n",
            "Train epoch 1: [33280/60000 (55%)]\tLoss: 0.105980\n",
            "Train epoch 1: [33600/60000 (56%)]\tLoss: 0.009514\n",
            "Train epoch 1: [33920/60000 (57%)]\tLoss: 0.001326\n",
            "Train epoch 1: [34240/60000 (57%)]\tLoss: 0.000860\n",
            "Train epoch 1: [34560/60000 (58%)]\tLoss: 0.006695\n",
            "Train epoch 1: [34880/60000 (58%)]\tLoss: 0.030219\n",
            "Train epoch 1: [35200/60000 (59%)]\tLoss: 0.000253\n",
            "Train epoch 1: [35520/60000 (59%)]\tLoss: 0.009100\n",
            "Train epoch 1: [35840/60000 (60%)]\tLoss: 0.003930\n",
            "Train epoch 1: [36160/60000 (60%)]\tLoss: 0.178818\n",
            "Train epoch 1: [36480/60000 (61%)]\tLoss: 0.002664\n",
            "Train epoch 1: [36800/60000 (61%)]\tLoss: 0.224780\n",
            "Train epoch 1: [37120/60000 (62%)]\tLoss: 0.004216\n",
            "Train epoch 1: [37440/60000 (62%)]\tLoss: 0.000094\n",
            "Train epoch 1: [37760/60000 (63%)]\tLoss: 0.030682\n",
            "Train epoch 1: [38080/60000 (63%)]\tLoss: 0.015853\n",
            "Train epoch 1: [38400/60000 (64%)]\tLoss: 0.040764\n",
            "Train epoch 1: [38720/60000 (65%)]\tLoss: 0.003700\n",
            "Train epoch 1: [39040/60000 (65%)]\tLoss: 0.006759\n",
            "Train epoch 1: [39360/60000 (66%)]\tLoss: 0.010320\n",
            "Train epoch 1: [39680/60000 (66%)]\tLoss: 0.007845\n",
            "Train epoch 1: [40000/60000 (67%)]\tLoss: 0.034233\n",
            "Train epoch 1: [40320/60000 (67%)]\tLoss: 0.000196\n",
            "Train epoch 1: [40640/60000 (68%)]\tLoss: 0.001120\n",
            "Train epoch 1: [40960/60000 (68%)]\tLoss: 0.006973\n",
            "Train epoch 1: [41280/60000 (69%)]\tLoss: 0.006541\n",
            "Train epoch 1: [41600/60000 (69%)]\tLoss: 0.000437\n",
            "Train epoch 1: [41920/60000 (70%)]\tLoss: 0.001313\n",
            "Train epoch 1: [42240/60000 (70%)]\tLoss: 0.008681\n",
            "Train epoch 1: [42560/60000 (71%)]\tLoss: 0.022114\n",
            "Train epoch 1: [42880/60000 (71%)]\tLoss: 0.034917\n",
            "Train epoch 1: [43200/60000 (72%)]\tLoss: 0.014045\n",
            "Train epoch 1: [43520/60000 (73%)]\tLoss: 0.015587\n",
            "Train epoch 1: [43840/60000 (73%)]\tLoss: 0.027113\n",
            "Train epoch 1: [44160/60000 (74%)]\tLoss: 0.009167\n",
            "Train epoch 1: [44480/60000 (74%)]\tLoss: 0.011764\n",
            "Train epoch 1: [44800/60000 (75%)]\tLoss: 0.005435\n",
            "Train epoch 1: [45120/60000 (75%)]\tLoss: 0.012858\n",
            "Train epoch 1: [45440/60000 (76%)]\tLoss: 0.000374\n",
            "Train epoch 1: [45760/60000 (76%)]\tLoss: 0.000860\n",
            "Train epoch 1: [46080/60000 (77%)]\tLoss: 0.010423\n",
            "Train epoch 1: [46400/60000 (77%)]\tLoss: 0.004499\n",
            "Train epoch 1: [46720/60000 (78%)]\tLoss: 0.000816\n",
            "Train epoch 1: [47040/60000 (78%)]\tLoss: 0.002023\n",
            "Train epoch 1: [47360/60000 (79%)]\tLoss: 0.000761\n",
            "Train epoch 1: [47680/60000 (79%)]\tLoss: 0.001611\n",
            "Train epoch 1: [48000/60000 (80%)]\tLoss: 0.002247\n",
            "Train epoch 1: [48320/60000 (81%)]\tLoss: 0.066881\n",
            "Train epoch 1: [48640/60000 (81%)]\tLoss: 0.000519\n",
            "Train epoch 1: [48960/60000 (82%)]\tLoss: 0.001227\n",
            "Train epoch 1: [49280/60000 (82%)]\tLoss: 0.237944\n",
            "Train epoch 1: [49600/60000 (83%)]\tLoss: 0.014825\n",
            "Train epoch 1: [49920/60000 (83%)]\tLoss: 0.053005\n",
            "Train epoch 1: [50240/60000 (84%)]\tLoss: 0.002402\n",
            "Train epoch 1: [50560/60000 (84%)]\tLoss: 0.156867\n",
            "Train epoch 1: [50880/60000 (85%)]\tLoss: 0.009451\n",
            "Train epoch 1: [51200/60000 (85%)]\tLoss: 0.011654\n",
            "Train epoch 1: [51520/60000 (86%)]\tLoss: 0.034182\n",
            "Train epoch 1: [51840/60000 (86%)]\tLoss: 0.031476\n",
            "Train epoch 1: [52160/60000 (87%)]\tLoss: 0.018630\n",
            "Train epoch 1: [52480/60000 (87%)]\tLoss: 0.013226\n",
            "Train epoch 1: [52800/60000 (88%)]\tLoss: 0.005512\n",
            "Train epoch 1: [53120/60000 (89%)]\tLoss: 0.003946\n",
            "Train epoch 1: [53440/60000 (89%)]\tLoss: 0.001500\n",
            "Train epoch 1: [53760/60000 (90%)]\tLoss: 0.021852\n",
            "Train epoch 1: [54080/60000 (90%)]\tLoss: 0.024521\n",
            "Train epoch 1: [54400/60000 (91%)]\tLoss: 0.036943\n",
            "Train epoch 1: [54720/60000 (91%)]\tLoss: 0.027167\n",
            "Train epoch 1: [55040/60000 (92%)]\tLoss: 0.002744\n",
            "Train epoch 1: [55360/60000 (92%)]\tLoss: 0.015638\n",
            "Train epoch 1: [55680/60000 (93%)]\tLoss: 0.009332\n",
            "Train epoch 1: [56000/60000 (93%)]\tLoss: 0.025817\n",
            "Train epoch 1: [56320/60000 (94%)]\tLoss: 0.027517\n",
            "Train epoch 1: [56640/60000 (94%)]\tLoss: 0.000597\n",
            "Train epoch 1: [56960/60000 (95%)]\tLoss: 0.002115\n",
            "Train epoch 1: [57280/60000 (95%)]\tLoss: 0.001093\n",
            "Train epoch 1: [57600/60000 (96%)]\tLoss: 0.016100\n",
            "Train epoch 1: [57920/60000 (97%)]\tLoss: 0.071878\n",
            "Train epoch 1: [58240/60000 (97%)]\tLoss: 0.000852\n",
            "Train epoch 1: [58560/60000 (98%)]\tLoss: 0.002877\n",
            "Train epoch 1: [58880/60000 (98%)]\tLoss: 0.034128\n",
            "Train epoch 1: [59200/60000 (99%)]\tLoss: 0.100041\n",
            "Train epoch 1: [59520/60000 (99%)]\tLoss: 0.002242\n",
            "Train epoch 1: [59840/60000 (100%)]\tLoss: 0.016524\n",
            "Test: Average loss: 0.0000, Accuracy: 32/10000 (0%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 64/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 96/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 128/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 160/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 192/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 224/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 255/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 287/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 319/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 349/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 381/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 413/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 444/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 475/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 507/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 539/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 571/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 603/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 635/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 666/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 697/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 728/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 760/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 792/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 824/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 856/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 888/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 919/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 950/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 982/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 1013/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1045/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1077/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 1108/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1140/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 1170/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1202/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 1232/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1263/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 1294/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1325/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1357/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 1388/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1420/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1451/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1483/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1514/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 1545/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1577/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1609/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1641/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 1672/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1703/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1735/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1766/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1798/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1830/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 1861/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 1892/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1924/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1956/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1988/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0009, Accuracy: 2017/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2049/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2081/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 2110/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2142/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2173/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2205/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2237/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 2268/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2300/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2332/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2364/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2395/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2426/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2457/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2489/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2521/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2553/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 2584/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 2615/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2647/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2679/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2711/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2743/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2775/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2807/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2839/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2870/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 2899/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2930/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2961/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2992/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3024/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3056/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3088/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3120/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3152/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3184/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3216/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3247/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3279/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3311/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3342/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 3373/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3405/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3437/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3469/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0009, Accuracy: 3500/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 3530/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3562/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3594/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3626/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3658/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3689/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3720/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3751/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3783/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3814/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3846/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3877/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3908/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3940/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3972/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4003/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4034/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4066/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4098/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 4129/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4160/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 4190/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4221/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4253/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4285/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4317/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4349/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4381/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4413/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 4444/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4475/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4506/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4538/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4569/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4601/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4633/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4664/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4694/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4726/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 4756/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4787/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4819/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4851/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4883/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4915/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4947/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4979/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5011/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5043/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5075/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5107/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5139/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5171/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5203/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5235/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 5266/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5298/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5330/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5362/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 5393/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5425/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5457/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5489/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5521/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5553/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5585/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5617/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5649/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5681/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5713/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5745/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5777/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5809/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5841/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 5872/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 5903/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5935/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5967/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5999/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6031/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6063/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 6094/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6126/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6158/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6190/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6222/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6254/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6286/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6318/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6350/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6382/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6414/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6446/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 6477/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 6506/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 6536/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 6567/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6599/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6631/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6663/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 6694/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6726/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6758/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6790/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 6821/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6853/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6885/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6917/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6949/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6981/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7013/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7045/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7077/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7109/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7141/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7173/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7205/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7237/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7269/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7301/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7333/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7365/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7397/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7429/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7461/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7493/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7525/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7557/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7589/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7621/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7653/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7685/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7717/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7749/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 7779/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 7810/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 7841/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7873/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7905/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7937/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7969/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8001/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8033/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8065/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8097/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8129/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8161/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8193/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8225/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8257/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8289/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8320/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8352/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8384/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8416/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8448/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8480/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8512/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8544/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8576/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8608/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8640/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8672/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8704/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8736/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8768/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8800/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8832/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8864/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8896/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8927/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8959/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8991/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9023/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9055/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9087/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9119/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9151/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9183/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9215/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9247/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9279/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9311/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9343/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9375/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9407/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9439/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9471/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9503/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9535/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 9565/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0013, Accuracy: 9593/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 9625/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 9655/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 9686/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 9718/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 9749/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9781/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 9811/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9843/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 9875/10000 (99%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9891/10000 (99%)\n",
            "\n",
            "Train epoch 2: [0/60000 (0%)]\tLoss: 0.009094\n",
            "Train epoch 2: [320/60000 (1%)]\tLoss: 0.001024\n",
            "Train epoch 2: [640/60000 (1%)]\tLoss: 0.179977\n",
            "Train epoch 2: [960/60000 (2%)]\tLoss: 0.008555\n",
            "Train epoch 2: [1280/60000 (2%)]\tLoss: 0.061595\n",
            "Train epoch 2: [1600/60000 (3%)]\tLoss: 0.010252\n",
            "Train epoch 2: [1920/60000 (3%)]\tLoss: 0.001379\n",
            "Train epoch 2: [2240/60000 (4%)]\tLoss: 0.000449\n",
            "Train epoch 2: [2560/60000 (4%)]\tLoss: 0.000204\n",
            "Train epoch 2: [2880/60000 (5%)]\tLoss: 0.000607\n",
            "Train epoch 2: [3200/60000 (5%)]\tLoss: 0.000573\n",
            "Train epoch 2: [3520/60000 (6%)]\tLoss: 0.003213\n",
            "Train epoch 2: [3840/60000 (6%)]\tLoss: 0.003021\n",
            "Train epoch 2: [4160/60000 (7%)]\tLoss: 0.035975\n",
            "Train epoch 2: [4480/60000 (7%)]\tLoss: 0.001802\n",
            "Train epoch 2: [4800/60000 (8%)]\tLoss: 0.000149\n",
            "Train epoch 2: [5120/60000 (9%)]\tLoss: 0.013248\n",
            "Train epoch 2: [5440/60000 (9%)]\tLoss: 0.000194\n",
            "Train epoch 2: [5760/60000 (10%)]\tLoss: 0.012822\n",
            "Train epoch 2: [6080/60000 (10%)]\tLoss: 0.000189\n",
            "Train epoch 2: [6400/60000 (11%)]\tLoss: 0.001830\n",
            "Train epoch 2: [6720/60000 (11%)]\tLoss: 0.000761\n",
            "Train epoch 2: [7040/60000 (12%)]\tLoss: 0.005879\n",
            "Train epoch 2: [7360/60000 (12%)]\tLoss: 0.002711\n",
            "Train epoch 2: [7680/60000 (13%)]\tLoss: 0.007745\n",
            "Train epoch 2: [8000/60000 (13%)]\tLoss: 0.003178\n",
            "Train epoch 2: [8320/60000 (14%)]\tLoss: 0.001167\n",
            "Train epoch 2: [8640/60000 (14%)]\tLoss: 0.055347\n",
            "Train epoch 2: [8960/60000 (15%)]\tLoss: 0.000264\n",
            "Train epoch 2: [9280/60000 (15%)]\tLoss: 0.000231\n",
            "Train epoch 2: [9600/60000 (16%)]\tLoss: 0.001111\n",
            "Train epoch 2: [9920/60000 (17%)]\tLoss: 0.000430\n",
            "Train epoch 2: [10240/60000 (17%)]\tLoss: 0.000494\n",
            "Train epoch 2: [10560/60000 (18%)]\tLoss: 0.004326\n",
            "Train epoch 2: [10880/60000 (18%)]\tLoss: 0.013712\n",
            "Train epoch 2: [11200/60000 (19%)]\tLoss: 0.018900\n",
            "Train epoch 2: [11520/60000 (19%)]\tLoss: 0.051112\n",
            "Train epoch 2: [11840/60000 (20%)]\tLoss: 0.005574\n",
            "Train epoch 2: [12160/60000 (20%)]\tLoss: 0.000464\n",
            "Train epoch 2: [12480/60000 (21%)]\tLoss: 0.000128\n",
            "Train epoch 2: [12800/60000 (21%)]\tLoss: 0.022870\n",
            "Train epoch 2: [13120/60000 (22%)]\tLoss: 0.000386\n",
            "Train epoch 2: [13440/60000 (22%)]\tLoss: 0.000506\n",
            "Train epoch 2: [13760/60000 (23%)]\tLoss: 0.038327\n",
            "Train epoch 2: [14080/60000 (23%)]\tLoss: 0.001791\n",
            "Train epoch 2: [14400/60000 (24%)]\tLoss: 0.005460\n",
            "Train epoch 2: [14720/60000 (25%)]\tLoss: 0.018846\n",
            "Train epoch 2: [15040/60000 (25%)]\tLoss: 0.013311\n",
            "Train epoch 2: [15360/60000 (26%)]\tLoss: 0.001163\n",
            "Train epoch 2: [15680/60000 (26%)]\tLoss: 0.003487\n",
            "Train epoch 2: [16000/60000 (27%)]\tLoss: 0.059681\n",
            "Train epoch 2: [16320/60000 (27%)]\tLoss: 0.000166\n",
            "Train epoch 2: [16640/60000 (28%)]\tLoss: 0.011162\n",
            "Train epoch 2: [16960/60000 (28%)]\tLoss: 0.025007\n",
            "Train epoch 2: [17280/60000 (29%)]\tLoss: 0.000356\n",
            "Train epoch 2: [17600/60000 (29%)]\tLoss: 0.000927\n",
            "Train epoch 2: [17920/60000 (30%)]\tLoss: 0.001059\n",
            "Train epoch 2: [18240/60000 (30%)]\tLoss: 0.000602\n",
            "Train epoch 2: [18560/60000 (31%)]\tLoss: 0.009234\n",
            "Train epoch 2: [18880/60000 (31%)]\tLoss: 0.011983\n",
            "Train epoch 2: [19200/60000 (32%)]\tLoss: 0.001285\n",
            "Train epoch 2: [19520/60000 (33%)]\tLoss: 0.000403\n",
            "Train epoch 2: [19840/60000 (33%)]\tLoss: 0.000207\n",
            "Train epoch 2: [20160/60000 (34%)]\tLoss: 0.000103\n",
            "Train epoch 2: [20480/60000 (34%)]\tLoss: 0.003276\n",
            "Train epoch 2: [20800/60000 (35%)]\tLoss: 0.051942\n",
            "Train epoch 2: [21120/60000 (35%)]\tLoss: 0.001479\n",
            "Train epoch 2: [21440/60000 (36%)]\tLoss: 0.001403\n",
            "Train epoch 2: [21760/60000 (36%)]\tLoss: 0.001649\n",
            "Train epoch 2: [22080/60000 (37%)]\tLoss: 0.000139\n",
            "Train epoch 2: [22400/60000 (37%)]\tLoss: 0.001161\n",
            "Train epoch 2: [22720/60000 (38%)]\tLoss: 0.006132\n",
            "Train epoch 2: [23040/60000 (38%)]\tLoss: 0.004544\n",
            "Train epoch 2: [23360/60000 (39%)]\tLoss: 0.003166\n",
            "Train epoch 2: [23680/60000 (39%)]\tLoss: 0.001033\n",
            "Train epoch 2: [24000/60000 (40%)]\tLoss: 0.000252\n",
            "Train epoch 2: [24320/60000 (41%)]\tLoss: 0.023066\n",
            "Train epoch 2: [24640/60000 (41%)]\tLoss: 0.007272\n",
            "Train epoch 2: [24960/60000 (42%)]\tLoss: 0.000204\n",
            "Train epoch 2: [25280/60000 (42%)]\tLoss: 0.000545\n",
            "Train epoch 2: [25600/60000 (43%)]\tLoss: 0.122206\n",
            "Train epoch 2: [25920/60000 (43%)]\tLoss: 0.000613\n",
            "Train epoch 2: [26240/60000 (44%)]\tLoss: 0.004598\n",
            "Train epoch 2: [26560/60000 (44%)]\tLoss: 0.005868\n",
            "Train epoch 2: [26880/60000 (45%)]\tLoss: 0.003446\n",
            "Train epoch 2: [27200/60000 (45%)]\tLoss: 0.000279\n",
            "Train epoch 2: [27520/60000 (46%)]\tLoss: 0.000149\n",
            "Train epoch 2: [27840/60000 (46%)]\tLoss: 0.050073\n",
            "Train epoch 2: [28160/60000 (47%)]\tLoss: 0.007079\n",
            "Train epoch 2: [28480/60000 (47%)]\tLoss: 0.112026\n",
            "Train epoch 2: [28800/60000 (48%)]\tLoss: 0.000490\n",
            "Train epoch 2: [29120/60000 (49%)]\tLoss: 0.019102\n",
            "Train epoch 2: [29440/60000 (49%)]\tLoss: 0.078530\n",
            "Train epoch 2: [29760/60000 (50%)]\tLoss: 0.012431\n",
            "Train epoch 2: [30080/60000 (50%)]\tLoss: 0.003282\n",
            "Train epoch 2: [30400/60000 (51%)]\tLoss: 0.005874\n",
            "Train epoch 2: [30720/60000 (51%)]\tLoss: 0.001708\n",
            "Train epoch 2: [31040/60000 (52%)]\tLoss: 0.095159\n",
            "Train epoch 2: [31360/60000 (52%)]\tLoss: 0.281640\n",
            "Train epoch 2: [31680/60000 (53%)]\tLoss: 0.000230\n",
            "Train epoch 2: [32000/60000 (53%)]\tLoss: 0.001720\n",
            "Train epoch 2: [32320/60000 (54%)]\tLoss: 0.133286\n",
            "Train epoch 2: [32640/60000 (54%)]\tLoss: 0.004656\n",
            "Train epoch 2: [32960/60000 (55%)]\tLoss: 0.000781\n",
            "Train epoch 2: [33280/60000 (55%)]\tLoss: 0.003686\n",
            "Train epoch 2: [33600/60000 (56%)]\tLoss: 0.045386\n",
            "Train epoch 2: [33920/60000 (57%)]\tLoss: 0.015805\n",
            "Train epoch 2: [34240/60000 (57%)]\tLoss: 0.000463\n",
            "Train epoch 2: [34560/60000 (58%)]\tLoss: 0.023280\n",
            "Train epoch 2: [34880/60000 (58%)]\tLoss: 0.003708\n",
            "Train epoch 2: [35200/60000 (59%)]\tLoss: 0.016783\n",
            "Train epoch 2: [35520/60000 (59%)]\tLoss: 0.083576\n",
            "Train epoch 2: [35840/60000 (60%)]\tLoss: 0.008108\n",
            "Train epoch 2: [36160/60000 (60%)]\tLoss: 0.000191\n",
            "Train epoch 2: [36480/60000 (61%)]\tLoss: 0.013134\n",
            "Train epoch 2: [36800/60000 (61%)]\tLoss: 0.002002\n",
            "Train epoch 2: [37120/60000 (62%)]\tLoss: 0.008175\n",
            "Train epoch 2: [37440/60000 (62%)]\tLoss: 0.001135\n",
            "Train epoch 2: [37760/60000 (63%)]\tLoss: 0.002287\n",
            "Train epoch 2: [38080/60000 (63%)]\tLoss: 0.026272\n",
            "Train epoch 2: [38400/60000 (64%)]\tLoss: 0.253987\n",
            "Train epoch 2: [38720/60000 (65%)]\tLoss: 0.009787\n",
            "Train epoch 2: [39040/60000 (65%)]\tLoss: 0.001663\n",
            "Train epoch 2: [39360/60000 (66%)]\tLoss: 0.000330\n",
            "Train epoch 2: [39680/60000 (66%)]\tLoss: 0.057465\n",
            "Train epoch 2: [40000/60000 (67%)]\tLoss: 0.036212\n",
            "Train epoch 2: [40320/60000 (67%)]\tLoss: 0.018253\n",
            "Train epoch 2: [40640/60000 (68%)]\tLoss: 0.038773\n",
            "Train epoch 2: [40960/60000 (68%)]\tLoss: 0.014050\n",
            "Train epoch 2: [41280/60000 (69%)]\tLoss: 0.002149\n",
            "Train epoch 2: [41600/60000 (69%)]\tLoss: 0.015738\n",
            "Train epoch 2: [41920/60000 (70%)]\tLoss: 0.000434\n",
            "Train epoch 2: [42240/60000 (70%)]\tLoss: 0.128207\n",
            "Train epoch 2: [42560/60000 (71%)]\tLoss: 0.231256\n",
            "Train epoch 2: [42880/60000 (71%)]\tLoss: 0.005154\n",
            "Train epoch 2: [43200/60000 (72%)]\tLoss: 0.001541\n",
            "Train epoch 2: [43520/60000 (73%)]\tLoss: 0.003528\n",
            "Train epoch 2: [43840/60000 (73%)]\tLoss: 0.035213\n",
            "Train epoch 2: [44160/60000 (74%)]\tLoss: 0.007167\n",
            "Train epoch 2: [44480/60000 (74%)]\tLoss: 0.000935\n",
            "Train epoch 2: [44800/60000 (75%)]\tLoss: 0.019251\n",
            "Train epoch 2: [45120/60000 (75%)]\tLoss: 0.004868\n",
            "Train epoch 2: [45440/60000 (76%)]\tLoss: 0.001680\n",
            "Train epoch 2: [45760/60000 (76%)]\tLoss: 0.024733\n",
            "Train epoch 2: [46080/60000 (77%)]\tLoss: 0.004926\n",
            "Train epoch 2: [46400/60000 (77%)]\tLoss: 0.001247\n",
            "Train epoch 2: [46720/60000 (78%)]\tLoss: 0.007635\n",
            "Train epoch 2: [47040/60000 (78%)]\tLoss: 0.086505\n",
            "Train epoch 2: [47360/60000 (79%)]\tLoss: 0.001364\n",
            "Train epoch 2: [47680/60000 (79%)]\tLoss: 0.023526\n",
            "Train epoch 2: [48000/60000 (80%)]\tLoss: 0.031835\n",
            "Train epoch 2: [48320/60000 (81%)]\tLoss: 0.106146\n",
            "Train epoch 2: [48640/60000 (81%)]\tLoss: 0.004756\n",
            "Train epoch 2: [48960/60000 (82%)]\tLoss: 0.005133\n",
            "Train epoch 2: [49280/60000 (82%)]\tLoss: 0.010013\n",
            "Train epoch 2: [49600/60000 (83%)]\tLoss: 0.040060\n",
            "Train epoch 2: [49920/60000 (83%)]\tLoss: 0.009646\n",
            "Train epoch 2: [50240/60000 (84%)]\tLoss: 0.033872\n",
            "Train epoch 2: [50560/60000 (84%)]\tLoss: 0.000802\n",
            "Train epoch 2: [50880/60000 (85%)]\tLoss: 0.031759\n",
            "Train epoch 2: [51200/60000 (85%)]\tLoss: 0.002358\n",
            "Train epoch 2: [51520/60000 (86%)]\tLoss: 0.013492\n",
            "Train epoch 2: [51840/60000 (86%)]\tLoss: 0.003379\n",
            "Train epoch 2: [52160/60000 (87%)]\tLoss: 0.003764\n",
            "Train epoch 2: [52480/60000 (87%)]\tLoss: 0.000446\n",
            "Train epoch 2: [52800/60000 (88%)]\tLoss: 0.000148\n",
            "Train epoch 2: [53120/60000 (89%)]\tLoss: 0.011535\n",
            "Train epoch 2: [53440/60000 (89%)]\tLoss: 0.000433\n",
            "Train epoch 2: [53760/60000 (90%)]\tLoss: 0.032051\n",
            "Train epoch 2: [54080/60000 (90%)]\tLoss: 0.197269\n",
            "Train epoch 2: [54400/60000 (91%)]\tLoss: 0.005140\n",
            "Train epoch 2: [54720/60000 (91%)]\tLoss: 0.016519\n",
            "Train epoch 2: [55040/60000 (92%)]\tLoss: 0.011107\n",
            "Train epoch 2: [55360/60000 (92%)]\tLoss: 0.009034\n",
            "Train epoch 2: [55680/60000 (93%)]\tLoss: 0.000601\n",
            "Train epoch 2: [56000/60000 (93%)]\tLoss: 0.003554\n",
            "Train epoch 2: [56320/60000 (94%)]\tLoss: 0.002573\n",
            "Train epoch 2: [56640/60000 (94%)]\tLoss: 0.004635\n",
            "Train epoch 2: [56960/60000 (95%)]\tLoss: 0.004192\n",
            "Train epoch 2: [57280/60000 (95%)]\tLoss: 0.000163\n",
            "Train epoch 2: [57600/60000 (96%)]\tLoss: 0.033983\n",
            "Train epoch 2: [57920/60000 (97%)]\tLoss: 0.030656\n",
            "Train epoch 2: [58240/60000 (97%)]\tLoss: 0.083949\n",
            "Train epoch 2: [58560/60000 (98%)]\tLoss: 0.003654\n",
            "Train epoch 2: [58880/60000 (98%)]\tLoss: 0.010737\n",
            "Train epoch 2: [59200/60000 (99%)]\tLoss: 0.018243\n",
            "Train epoch 2: [59520/60000 (99%)]\tLoss: 0.002022\n",
            "Train epoch 2: [59840/60000 (100%)]\tLoss: 0.016613\n",
            "Test: Average loss: 0.0000, Accuracy: 32/10000 (0%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 64/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 96/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 127/10000 (1%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 159/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 191/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 223/10000 (2%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 254/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 286/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 318/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 349/10000 (3%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 381/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 413/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 444/10000 (4%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 475/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 507/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 539/10000 (5%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 571/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 603/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 635/10000 (6%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 666/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 698/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 730/10000 (7%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 761/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 793/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 825/10000 (8%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 857/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 888/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 920/10000 (9%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 951/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 983/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 1014/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1045/10000 (10%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1077/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 1108/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1139/10000 (11%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 1168/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1200/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0007, Accuracy: 1229/10000 (12%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1260/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1291/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 1322/10000 (13%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1354/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 1385/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1417/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1449/10000 (14%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1481/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1513/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1545/10000 (15%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1577/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1609/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1641/10000 (16%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1673/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1705/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1737/10000 (17%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1769/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1801/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1833/10000 (18%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 1864/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 1895/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1927/10000 (19%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 1959/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 1991/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 2022/10000 (20%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2054/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0004, Accuracy: 2084/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0011, Accuracy: 2113/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2144/10000 (21%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2175/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2207/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2239/10000 (22%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2271/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2303/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2335/10000 (23%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2367/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2399/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 2430/10000 (24%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2462/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2494/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2526/10000 (25%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2558/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 2589/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0011, Accuracy: 2620/10000 (26%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2652/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2684/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2716/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2748/10000 (27%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2780/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2812/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 2844/10000 (28%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 2875/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0008, Accuracy: 2904/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2935/10000 (29%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2966/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 2997/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3029/10000 (30%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3061/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3093/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3125/10000 (31%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3157/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3189/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3221/10000 (32%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3253/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3285/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3317/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3349/10000 (33%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3380/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3412/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3444/10000 (34%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3476/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 3507/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3538/10000 (35%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3570/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 3601/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3633/10000 (36%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3665/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3696/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3727/10000 (37%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3758/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3790/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 3821/10000 (38%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3853/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 3884/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3916/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3948/10000 (39%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 3980/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4012/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4044/10000 (40%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4076/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4108/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 4139/10000 (41%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4170/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 4200/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4232/10000 (42%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4264/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4295/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4327/10000 (43%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4359/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4390/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4422/10000 (44%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4454/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4485/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 4515/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4547/10000 (45%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4578/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4610/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4641/10000 (46%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4672/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 4702/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4734/10000 (47%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 4766/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 4797/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4829/10000 (48%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4861/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4893/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4925/10000 (49%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4957/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 4989/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5021/10000 (50%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5053/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5085/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5117/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 5148/10000 (51%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5180/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5212/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5244/10000 (52%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5276/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5308/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5340/10000 (53%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5372/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5404/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5436/10000 (54%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5468/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5500/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5532/10000 (55%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5564/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 5596/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5628/10000 (56%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5660/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5692/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5724/10000 (57%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5756/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5788/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5820/10000 (58%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5852/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 5883/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 5914/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 5945/10000 (59%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 5977/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6009/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6041/10000 (60%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6073/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6105/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6137/10000 (61%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6169/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6201/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6233/10000 (62%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6265/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6297/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6329/10000 (63%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6361/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6393/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6425/10000 (64%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6457/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 6488/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 6517/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 6548/10000 (65%)\n",
            "\n",
            "Test: Average loss: 0.0005, Accuracy: 6578/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6610/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6642/10000 (66%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 6674/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6706/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6738/10000 (67%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6770/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6802/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6834/10000 (68%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6866/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6898/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6930/10000 (69%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6962/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 6994/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7026/10000 (70%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7058/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7090/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7122/10000 (71%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7154/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7186/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7218/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7250/10000 (72%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7282/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7314/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7346/10000 (73%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7378/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7410/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7442/10000 (74%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7474/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7506/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7538/10000 (75%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7570/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7602/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7634/10000 (76%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7666/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7698/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7730/10000 (77%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7762/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7794/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7826/10000 (78%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 7858/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7890/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7922/10000 (79%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 7954/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 7986/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 8018/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8050/10000 (80%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8082/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8114/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8146/10000 (81%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8177/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8209/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8241/10000 (82%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8273/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8305/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8337/10000 (83%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8369/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8401/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8433/10000 (84%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 8465/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8497/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8529/10000 (85%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8561/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8593/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8625/10000 (86%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8657/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8689/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8721/10000 (87%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8753/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8785/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8817/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8849/10000 (88%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8881/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8913/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 8944/10000 (89%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 8976/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9008/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9040/10000 (90%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9072/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9104/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9136/10000 (91%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9168/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9200/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9232/10000 (92%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9264/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9296/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 9328/10000 (93%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9360/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9392/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9424/10000 (94%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9456/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9488/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9520/10000 (95%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9552/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 9582/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0009, Accuracy: 9611/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0001, Accuracy: 9643/10000 (96%)\n",
            "\n",
            "Test: Average loss: 0.0006, Accuracy: 9673/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9705/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 9736/10000 (97%)\n",
            "\n",
            "Test: Average loss: 0.0002, Accuracy: 9767/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9799/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0003, Accuracy: 9830/10000 (98%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9862/10000 (99%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9894/10000 (99%)\n",
            "\n",
            "Test: Average loss: 0.0000, Accuracy: 9910/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save checkpoint"
      ],
      "metadata": {
        "id": "PnC5e91rKExb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to save ckpt, please add a path first\n",
        "torch.save({\n",
        "    'epoch': nb_epochs,\n",
        "    'model_state_dict': our_model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, \"INSERT_PATH\")"
      ],
      "metadata": {
        "id": "dxfmUYJiKEI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrain/Fine-tune our CNN"
      ],
      "metadata": {
        "id": "y_Q5c71mM14f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load checkpoint"
      ],
      "metadata": {
        "id": "GXw0JHhxKa-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To load the checkpoint, use the 'torch.load()' function. Here's an example:\n",
        "new_model = BasicCNN() # load a new model with the same structure\n",
        "new_optimizer = optim.SGD(new_model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#retrieve and load checkpoint onto the new model and optimizer\n",
        "checkpoint = torch.load(\"INSERT_PATH\")\n",
        "new_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "new_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "continue_epoch = checkpoint['epoch']"
      ],
      "metadata": {
        "id": "IBcBLdo9Kc_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Continue training model or fine-tune"
      ],
      "metadata": {
        "id": "JFNFYeMkMZxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 1\n",
        "\n",
        "for epoch in range(nb_epochs):\n",
        "    train(new_model, trainloader, new_optimizer, epoch, cuda)\n",
        "    test(new_model, testloader, cuda)"
      ],
      "metadata": {
        "id": "ClKkECpSMZfl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}